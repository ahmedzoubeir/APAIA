import time
import pandas as pd
from groq import Groq

# Initialize the Groq client with API key directly
api_key = "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"
client = Groq(api_key=api_key)

# Load the dataset
input_file = "cve_rcm_filtered.csv"
df = pd.read_csv(input_file)

# Function to call Groq API and get a response
def get_llama_response(prompt):
    try:
        # Create a streaming completion request
        completion = client.chat.completions.create(
            model="llama3-8b-8192",
            messages=[
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=1,
            max_tokens=1024,
            top_p=1,
            stream=True,
            stop=None,
        )

        # Collect the response chunks
        response_text = ""
        for chunk in completion:
            response_text += chunk.choices[0].delta.content or ""
        
        return response_text.strip()
    except Exception as e:
        print(f"Error: {e}")
        return None

# Iterate over each row and get Llama's response for the Prompt
output_file = "llama_responses_rcm.csv"
df['Llama_Response'] = None  # Add a new column to store responses

for index, row in df.iterrows():
    print(f"Processing row {index+1}/{len(df)}")
    prompt = row['Prompt']
    if pd.notna(prompt) and prompt.strip():
        response = get_llama_response(prompt)
        df.at[index, 'Llama_Response'] = response
        print(f"Response for row {index+1}: {response}")  # Debug: Print response
    else:
        print(f"Row {index+1} has an empty or invalid prompt.")
    
    # Save the current state of the dataframe to the output file
    df.to_csv(output_file, index=False)
    
    time.sleep(4)  # Delay between requests to avoid rate limits

print(f"Responses saved to {output_file}")
